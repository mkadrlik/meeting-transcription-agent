# Meeting Transcription Agent Environment Configuration
# Copy this file to .env and set your actual values

# Local Whisper Configuration (CPU-only transcription)
WHISPER_MODEL_SIZE=base
# Options: tiny, base, small, medium, large
# Smaller models = faster processing, lower accuracy
# Larger models = slower processing, higher accuracy

# Ollama Post-Processing Configuration
OLLAMA_URL=http://192.168.50.15:11434
OLLAMA_MODEL=gemma3-4b
# Your Ollama instance URL and model name for transcript enhancement

# Audio Configuration (used by start_recording tool)
DEFAULT_SAMPLE_RATE=16000
DEFAULT_CHANNELS=1
DEFAULT_CHUNK_DURATION=30

# Server Configuration
MAX_CONCURRENT_SESSIONS=5
SESSION_TIMEOUT=3600
DEFAULT_TRANSCRIPTION_PROVIDER=whisper_local

# Transcription Settings
TRANSCRIPTION_CONFIDENCE_THRESHOLD=0.5

# External MCP Gateway Configuration
# Point this to your existing MCP Gateway instance
MCP_GATEWAY_URL=http://192.168.50.20:9000

# Export Configuration
EXPORTS_DIRECTORY=/tmp/transcripts

# Logging Configuration
LOG_LEVEL=INFO
LOG_FILE=/app/logs/transcription.log

# Audio Mode Configuration
DISABLE_AUDIO_CAPTURE=true
CLIENT_AUDIO_FORWARDING_ONLY=true

# Development Settings (uncomment for development)
# PYTHONPATH=/app
# DEBUG=true
